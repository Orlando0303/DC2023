{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业4：线性模型的分布式算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第1题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先利用如下代码生成模拟数据，并写入文件。数据中最后一列代表因变量 $Y$，其余列为自变量 $X$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=100)\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 100000\n",
    "p = 100\n",
    "x = np.random.normal(size=(n, p))\n",
    "beta = np.random.normal(size=p)\n",
    "y = 1.23 + x.dot(beta) + np.random.normal(scale=2.0, size=n)\n",
    "dat = np.hstack((x, y.reshape(n, 1)))\n",
    "np.savetxt(\"reg_data.txt\", dat, fmt=\"%.8f\", delimiter=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请以单机模式启动 PySpark，使用4个 CPU 核心，并编写分布式程序，实现如下计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002167FAAD480>\n",
      "<SparkContext master=local[4] appName=Regression>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# 本地模式\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[4]\").\\\n",
    "    appName(\"Regression\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "#sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 打印数据的前5行，并将每行的字符串截断至80个字符："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.08563060;0.99734545;0.28297850;-1.50629471;-0.57860025;1.65143654;-2.42667924...\n",
      "0.64205469;-1.97788793;0.71226464;2.59830393;-0.02462598;0.03414213;0.17954948;-...\n",
      "0.70331012;-0.59810533;2.20070210;0.68829693;-0.00630725;-0.20666230;-0.08652229...\n",
      "0.76505485;-0.82898883;-0.65915131;0.61112355;-0.14401335;1.31660560;-0.70434215...\n",
      "1.53409029;-0.52991410;-0.49097228;-1.30916531;-0.00866047;0.97681298;-1.7510703...\n"
     ]
    }
   ],
   "source": [
    "file = sc.textFile(\"reg_data.txt\")\n",
    "\n",
    "text = file.map(lambda x:x[:80]+'...').take(5)\n",
    "print(*text,sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 将读取数据后得到的 RDD 按分区转为矩阵。使用默认分区数，无需重新分区。打印出转换后的第一个非空分区所包含的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_vec(line):\n",
    "    str_vec = line.split(';')\n",
    "    num_vec = map(lambda x: float(x),str_vec)\n",
    "    return np.fromiter(num_vec, dtype=float)\n",
    "\n",
    "def part_to_mat(rdd):\n",
    "    rdd_arr = map(str_to_vec,rdd)\n",
    "    data_list = list(rdd_arr)\n",
    "    if len(data_list) < 1:\n",
    "        mat = np.array([])\n",
    "    else:\n",
    "        mat = np.vstack(data_list)\n",
    "    yield mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.0856306    0.99734545   0.2829785  ...   0.37940061  -0.37917643   3.72488966]\n",
      " [  0.64205469  -1.97788793   0.71226464 ...  -0.34126172  -0.21794626  10.98088055]\n",
      " [  0.70331012  -0.59810533   2.2007021  ...   0.16054442   0.81976061 -12.63028846]\n",
      " ...\n",
      " [ -0.30751248   0.1323937    2.33256448 ...   0.37475498  -1.37608098 -13.52353737]\n",
      " [ -0.02266014  -0.3014796    2.34502536 ...  -2.06082696  -1.20995417 -10.00714174]\n",
      " [  0.02415432  -0.3896902   -0.07492828 ...  -0.41935638  -1.68496516   8.33748658]]\n"
     ]
    }
   ],
   "source": [
    "dat = file.mapPartitions(part_to_mat).filter(lambda x: x.shape[0]>0)\n",
    "print(dat.first())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 估计线性回归模型 $Y=X\\beta+\\varepsilon$ 的回归系数，**同时包含截距项**。要求**只使用一次** `reduce()`。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归系数估计值的显式解为 $\\hat{\\beta}=(X'X)^{-1}X'y$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.22841355, -0.58056172, -1.12947488,  1.16031679,  0.68276231,  0.64063205, -1.69803101,\n",
       "        0.87295008, -0.6827681 ,  1.21323821, -0.18532546, -0.60313748,  0.45016343,  1.54732259,\n",
       "        0.93536575,  0.33661885, -0.62839196, -0.18223468,  1.04004336,  0.99530527, -0.22421889,\n",
       "        0.26910036, -1.95584105,  0.93200566, -0.46663344, -1.30308226, -1.07451859, -0.9200001 ,\n",
       "       -0.4751849 , -0.41498631,  0.0893936 ,  0.74250157,  0.44142653,  0.78310696,  0.0968675 ,\n",
       "       -0.20661749,  1.36408459, -0.84452182, -1.56303708, -0.03391736,  0.05672465, -0.01335776,\n",
       "       -0.31919022, -1.7366497 , -1.35682179, -1.60938262, -1.28888311,  0.92820726,  0.9148462 ,\n",
       "       -0.87189391, -1.11327839, -0.65324334, -1.54752238, -1.48016168, -1.40044728,  0.06124555,\n",
       "       -2.06832355,  0.23966887, -1.45310857, -0.4958114 , -1.0917562 ,  1.22608413,  0.71866161,\n",
       "        0.46548143, -0.21573557,  1.19919219, -0.18470024,  0.41716831,  0.48748654, -0.28702665,\n",
       "       -0.92945413, -2.54835305,  1.21073672, -0.41380347,  0.40696645,  0.74054168,  1.59228068,\n",
       "       -0.35873326,  0.41181034, -1.44030368, -0.47743396, -0.27652029, -1.65913574,  1.16482342,\n",
       "        0.42295274,  0.22050512, -0.59462348,  1.16788557, -2.2204779 , -0.5005211 , -1.10794934,\n",
       "        1.6138532 , -1.31890072, -0.06216637,  2.21620451,  1.48179503,  0.54913153, -0.73276144,\n",
       "        0.4414304 ,  2.14035783,  1.68434134])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dat.map(lambda part: np.hstack((np.ones((part.shape[0],1)), part)))\n",
    "xtx, xty = data.map(lambda part: (part[:, :p+1].T.dot(part[:, :p+1]), part[:, :p+1].T.dot(part[:, p+1]))).\\\n",
    "    reduce(lambda x, y: (x[0]+y[0],x[1]+y[1]))\n",
    "bhat = np.linalg.solve(xtx, xty)\n",
    "bhat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 设计一个分布式算法，计算回归模型的 $R^2$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9654393907479705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse, sst = data.map(lambda part: (\n",
    "    np.sum((part[:, p+1]-part[:, :p+1].dot(bhat))**2), \n",
    "    np.sum((part[:, p+1]-np.mean(part[:, p+1]))**2))).\\\n",
    "    reduce(lambda x, y: (x[0]+y[0],x[1]+y[1]))\n",
    "R2 = 1 - sse/sst\n",
    "R2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第2题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 考虑 Softplus 函数 $$\\mathrm{softplus}(x)=\\log(1+e^x)$$\n",
    "\n",
    "请利用 Numpy 编写一个函数 `softplus(x)`，令其可以接收一个向量或矩阵 `x`，返回 Softplus 函数在 `x` 上的取值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softplus(x):\n",
    "    return np.log(1.0 + np.exp(x))\n",
    "    # 此处插入代码"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个简单的测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 4.53988992e-05 6.93147181e-01 1.31326169e+00 1.00000454e+01\n",
      " 1.00000000e+02            inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Orlando\\AppData\\Local\\Temp\\ipykernel_9544\\3717958442.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1.0 + np.exp(x))\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1000.0, -100.0, -10.0, 0.0, 1.0, 10.0, 100.0, 1000.0])\n",
    "\n",
    "# 上面编写的函数\n",
    "print(softplus(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 上述结果是否正常？如果出现异常取值，思考可能的原因是什么，并参照课件上的说明再次尝试编写 Softplus 函数。注意尽可能使用 Numpy 提供的向量化函数，避免使用循环。该函数需同时支持向量和矩阵参数。如果一切正常，可忽略此问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出现了inf无穷大，因为x很大时，exp（x）溢出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    # 此处插入代码\n",
    "    sx = np.where(x < 0, np.log(1.0 + np.exp(x)), x + np.log(1.0 + np.exp(-x)))\n",
    "    return sx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 4.53988992e-05 6.93147181e-01 1.31326169e+00 1.00000454e+01\n",
      " 1.00000000e+02 1.00000000e+03]\n",
      "\n",
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [4.53988992e-05 6.93147181e-01]\n",
      " [1.31326169e+00 1.00000454e+01]\n",
      " [1.00000000e+02 1.00000000e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Orlando\\AppData\\Local\\Temp\\ipykernel_9544\\4085682220.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  sx = np.where(x < 0, np.log(1.0 + np.exp(x)), x + np.log(1.0 + np.exp(-x)))\n"
     ]
    }
   ],
   "source": [
    "print(softplus(x))\n",
    "print()\n",
    "print(softplus(x.reshape(4, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第3题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用如下代码生成模拟数据，其中数据第一列代表0-1因变量 $Y$，其余列为自变量 $X$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 100000\n",
    "p = 100\n",
    "x = np.random.normal(size=(n, p))\n",
    "beta = np.random.normal(size=p)\n",
    "prob = expit(-0.5 + x.dot(beta))  # p = 1 / (1 + exp(-x * beta))\n",
    "y = np.random.binomial(1, prob, size=n)\n",
    "dat = np.hstack((y.reshape(n, 1), x))\n",
    "np.savetxt(\"logistic_data.txt\", dat, fmt=\"%.8f\", delimiter=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对上述数据建立 Logistic 回归模型。任选一种算法，估计 Logistic 回归的回归系数，**同时包含截距项**。请利用第2题中编写的 Softplus 函数，编写**数值稳定**的函数计算 Logistic 回归的目标函数和梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[119] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "file = sc.textFile(\"logistic_data.txt\")\n",
    "\n",
    "def str_to_vec(line):\n",
    "    str_vec = line.split('\\t')\n",
    "    num_vec = map(lambda x: float(x),str_vec)\n",
    "    return np.fromiter(num_vec, dtype=float)\n",
    "\n",
    "def part_to_mat(rdd):\n",
    "    rdd_arr = map(str_to_vec,rdd)\n",
    "    data_list = list(rdd_arr)\n",
    "    if len(data_list) < 1:\n",
    "        mat = np.array([])\n",
    "    else:\n",
    "        mat = np.vstack(data_list)\n",
    "    yield mat\n",
    "\n",
    "dat = file.mapPartitions(part_to_mat).filter(lambda x: x.shape[0]>0)\n",
    "data = dat.map(lambda part: np.hstack((part, np.ones((part.shape[0],1)))))\n",
    "data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, objfn = 69314.71805599453, resid = 1.5698521885255374\n",
      "Iteration 1, objfn = 32646.97922791124, resid = 1.390199746226831\n",
      "Iteration 2, objfn = 21647.76931828451, resid = 1.736878881587562\n",
      "Iteration 3, objfn = 16036.817158222435, resid = 2.077661047626656\n",
      "Iteration 4, objfn = 13369.971015111048, resid = 2.055442578945903\n",
      "Iteration 5, objfn = 12424.605050958291, resid = 1.3106763115298783\n",
      "Iteration 6, objfn = 12255.539828228106, resid = 0.34684153390742634\n",
      "Iteration 7, objfn = 12248.214989925482, resid = 0.018344346618315865\n",
      "Iteration 8, objfn = 12248.196924487687, resid = 6.370796265214652e-05\n",
      "Iteration 9, objfn = 12248.19692427128, resid = 6.056471730067524e-08\n",
      "\n",
      "finished in 29.549819231033325 seconds\n"
     ]
    }
   ],
   "source": [
    "def compute_stats(part_mat, beta_old):\n",
    "    # 提取 X 和 y\n",
    "    y = part_mat[:, 0]\n",
    "    x = part_mat[:, 1:]\n",
    "    # X * beta\n",
    "    xb = x.dot(beta_old)\n",
    "    # rho(X * beta)\n",
    "    prob = expit(xb)\n",
    "    # W 的对角线元素\n",
    "    w = prob * (1.0 - prob) + 1e-6\n",
    "    # X'W，数组广播操作，避免生成完整的 W\n",
    "    xtw = x.transpose() * w\n",
    "    # X'WX\n",
    "    xtwx = xtw.dot(x)\n",
    "    # X'Wz\n",
    "    z = xb + (y - prob) / w\n",
    "    xtwz = xtw.dot(z)\n",
    "    # 目标函数：sum(y * log(prob) + (1 - y) * log(1 - prob))\n",
    "    # softplus(x) = log(1+exp(x))\n",
    "    objfn = -np.sum(y * xb - softplus(xb))\n",
    "\n",
    "    return xtwx, xtwz, objfn\n",
    "\n",
    "# 根据数据动态获取维度，不要使用之前模拟时的变量\n",
    "p = data.first().shape[1] - 1\n",
    "# beta 初始化为 0 向量\n",
    "beta_hat = np.zeros(p)\n",
    "# 记录目标函数值\n",
    "objvals = []\n",
    "\n",
    "# 最大迭代次数\n",
    "maxit = 20\n",
    "# 收敛条件\n",
    "eps = 1e-6\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(maxit):\n",
    "    # 完整数据的 X'WX 和 X'Wz 是各分区的加和\n",
    "    xtwx, xtwz, objfn = data.map(lambda part: compute_stats(part, beta_hat)).\\\n",
    "        reduce(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    # 计算新 beta\n",
    "    beta_new = np.linalg.solve(xtwx, xtwz)\n",
    "    # 计算 beta 的变化\n",
    "    resid = np.linalg.norm(beta_new - beta_hat)\n",
    "    print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "    objvals.append(objfn)\n",
    "    # 如果 beta 几乎不再变化，退出循环\n",
    "    if resid < eps:\n",
    "        break\n",
    "    # 更新 beta\n",
    "    beta_hat = beta_new\n",
    "t2 = time.time()\n",
    "print(f\"\\nfinished in {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59176196 -1.10420803  1.1546564   0.67280846  0.63931464 -1.68220071  0.86041452 -0.69834251\n",
      "  1.22446393 -0.21062583 -0.60143279  0.44213217  1.57506739  0.93504494  0.34283382 -0.63115954\n",
      " -0.16737269  1.03564847  0.9885046  -0.21736314  0.26608044 -1.9546613   0.93399147 -0.44097986\n",
      " -1.32382408 -1.06955406 -0.93365571 -0.47879284 -0.40975603  0.13045673  0.72407648  0.43211279\n",
      "  0.78064486  0.12355277 -0.20116152  1.34425232 -0.8467126  -1.57109621 -0.02174217  0.04202859\n",
      "  0.01757209 -0.33735364 -1.74371023 -1.32742343 -1.60007017 -1.28377679  0.93921256  0.93254572\n",
      " -0.84857908 -1.08700601 -0.65543369 -1.52634259 -1.46037052 -1.41541159  0.06736292 -2.06484347\n",
      "  0.25380448 -1.44377969 -0.45925857 -1.12439824  1.24274755  0.72115264  0.46168381 -0.20588244\n",
      "  1.19789065 -0.17370143  0.42621562  0.49622293 -0.29831759 -0.93076696 -2.52159476  1.21260763\n",
      " -0.40380623  0.41771335  0.75208194  1.5969521  -0.36537673  0.40531527 -1.43161884 -0.46412512\n",
      " -0.29281007 -1.65346949  1.14670833  0.43075961  0.22169932 -0.58293427  1.16006918 -2.22283069\n",
      " -0.48986113 -1.09011805  1.60996124 -1.30410678 -0.04627443  2.22581121  1.44926055  0.53314052\n",
      " -0.7187001   0.47181894  2.1395752   1.64523326 -0.52097596]\n",
      "\n",
      "69314.71805599453\n",
      "32646.97922791124\n",
      "21647.76931828451\n",
      "16036.817158222435\n",
      "13369.971015111048\n",
      "12424.605050958291\n",
      "12255.539828228106\n",
      "12248.214989925482\n",
      "12248.196924487687\n",
      "12248.19692427128\n",
      "\n",
      "6.056471730067524e-08\n"
     ]
    }
   ],
   "source": [
    "print(beta_hat)  #包含截距项\n",
    "print()\n",
    "print(*objvals,sep='\\n')  #目标函数\n",
    "print()\n",
    "print(resid)  #梯度"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 利用估计得到的 $\\hat{\\beta}$ 对原始数据进行预测，令 $\\hat{\\rho}_i$ 表示估计出的每个观测 $Y_i$ 取值为1的概率。为每个观测计算一个预测的0-1标签 $\\hat{l}_i$，规则如下：如果 $\\hat{\\rho}_i\\ge 0.5$，则 $\\hat{l}_i=1$，反之 $\\hat{l}_i=0$。利用分布式算法计算模型的预测准确度，即 $n^{-1}\\sum_{i=1}^n I(Y_i=\\hat{l}_i)$。$I(Y_i=\\hat{l}_i)$ 表示预测对取1，预测错取0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94737\n"
     ]
    }
   ],
   "source": [
    "def pred(part_mat, bhat):\n",
    "    x = part_mat[:, 1:]\n",
    "    # X * beta\n",
    "    xb = x.dot(bhat)\n",
    "    # rho(X * beta)\n",
    "    prob = expit(xb)\n",
    "    li = np.where(prob>=0.5, 1, 0)\n",
    "    return li\n",
    "\n",
    "acc = data.map(lambda part: np.sum(np.where(pred(part, beta_hat)==part[:, 0], 1, 0))).reduce(lambda x,y: x + y)\n",
    "ACC = acc/n\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
